#!/usr/bin/env coffee

childProcess = require('child_process')
path = require('path')
fs = require('fs')
SparseVector = require('../lib/vector')
language = require('../lib/language')

parallelism = 1 #Math.floor(require('os').cpus().length / 2)
ITERATIONS = 10
SEED_PATH = path.join(__dirname, '../build/seed.json')

if fs.existsSync(SEED_PATH)
  console.warn("#{new Date}\tFound existing seed at #{SEED_PATH}. Using it. Delete to start from ZERO")
  seed = new SparseVector(JSON.parse(fs.readFileSync(SEED_PATH)))
else
  seed = SparseVector.zero()

raw = ""
process.stdin.on('data', (chunk) ->
  raw += chunk
)

process.stdin.on('end', ->
  trainings = (JSON.parse(line) for line in raw.split('\n') when line.trim() != '')
  hunkSize = Math.ceil(trainings.length / parallelism)
  children = []

  iterate = (i, trainings, seed) ->
    fs.writeFileSync(SEED_PATH, JSON.stringify(seed.hash))
    process.exit() if i == 0

    console.warn("#{new Date()}\tTraining iteration #{ITERATIONS - i + 1}")
    workersFinished = 0
    for j in [0...parallelism]
      do ->
        console.warn("#{new Date}\tForking child #{j}")
        child =
          childProcess.spawn(
            './node_modules/coffee-script/bin/coffee',
            ['--nodejs', '--max-old-space-size=4096', path.join(__dirname, 'train-worker'), SEED_PATH],
            stdio: ['pipe', 'pipe', process.stderr]
          )
        output = ""
        child.stdout.on('data', (chunk) ->
          output += chunk
        )
        child.stdout.on('end', ->
          seed.plusEq(JSON.parse(output))
          if workersFinished++ == parallelism - 1
            iterate(i - 1, trainings, seed)
        )
        for training in trainings.slice(j * hunkSize, (j+1) * hunkSize)
          child.stdin.write(JSON.stringify(training) + '\n')
        child.stdin.end()

  iterate(ITERATIONS, trainings, seed)
)

process.stdin.resume()