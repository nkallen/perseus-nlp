#!/usr/bin/env coffee --nodejs --prof

fs = require('fs')
path = require('path')
Perceptron = require('../lib/perceptron')
Viterbi = require('../lib/viterbi')
vector = require('../lib/vector')
Featurizer = require('../lib/featurizer')
Morpheus = require('../lib/morpheus')
Labelizer = require('../lib/labelizer')

MAX_TABLE_WIDTH = 193

iterations = Number(process.argv[3]) || 1

seedPath = process.argv[2]
if fs.existsSync(seedPath)
  seed = JSON.parse(fs.readFileSync(seedPath))
else
  seed = vector.zero()

allLabels = JSON.parse(fs.readFileSync(path.join(__dirname, '../resources/labels.json')))
nounLabels = ('proper-' + label for label in allLabels when /^noun/.test(label))
morpheus = new Morpheus(JSON.parse(fs.readFileSync(path.join(__dirname, '../build/morpheus.unaccentuated.json'))))

featurizer = new Featurizer(morpheus)
labelizer = new Labelizer(morpheus, nounLabels)
perceptron = new Perceptron(featurizer, labelizer, (scorer) -> new Viterbi(scorer, MAX_TABLE_WIDTH))

raw = ""
process.stdin.on('data', (chunk) ->
  raw += chunk
)

process.stdin.on('end', ->
  console.warn("#{new Date}\tProcessing Chunk")
  trainings = (JSON.parse(line) for line in raw.split(/\n/) when line.trim() != '')
  trained = perceptron.applyWithoutValidate(trainings, iterations, seed)
  process.stdout.write(JSON.stringify(trained, null, 2))
)

process.stdin.resume()